{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e66e066-9705-4af7-9866-922fd77dbd9c",
   "metadata": {},
   "source": [
    "### 1) What is Simple Linear Regression?\n",
    "Simple Linear Regression is a statistical method used to model the relationship between two continuous variables. It assumes that one variable (dependent variable, Y) can be predicted or explained by the other variable (independent variable, X) using a straight line.\n",
    "\n",
    "The equation for simple linear regression is:\n",
    "$$ Y = mX + c $$\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) is the dependent variable,\n",
    "- \\( X \\) is the independent variable,\n",
    "- \\( m \\) is the slope of the line,\n",
    "- \\( c \\) is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cac8f0-4867-4099-b463-ffc18e17b8e4",
   "metadata": {},
   "source": [
    "### 2) What are the key assumptions of Simple Linear Regression?\n",
    "The key assumptions for simple linear regression are:\n",
    "1. **Linearity**: The relationship between the dependent and independent variables is linear.\n",
    "2. **Independence**: The observations are independent of each other.\n",
    "3. **Homoscedasticity**: The variance of errors is constant across all levels of the independent variable.\n",
    "4. **Normality**: The residuals (errors) of the model are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff183e-3500-4a58-b426-ae7a7ae1e3eb",
   "metadata": {},
   "source": [
    "### 3) What does the coefficient m represent in the equation Y = mX + c?\n",
    "The coefficient \\( m \\) represents the **slope** of the regression line. It indicates how much the dependent variable \\( Y \\) is expected to change for a one-unit change in the independent variable \\( X \\).\n",
    "\n",
    "For example, if \\( m = 2 \\), it means that for each unit increase in \\( X \\), the value of \\( Y \\) increases by 2 units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc636d-aa66-4f71-82e1-06cfaa64ccd7",
   "metadata": {},
   "source": [
    "### 4) What does the intercept c represent in the equation Y = mX + c?\n",
    "The intercept \\( c \\) represents the value of the dependent variable \\( Y \\) when the independent variable \\( X \\) is equal to zero. It is the point where the regression line crosses the Y-axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602edb2-d8c1-4d96-997e-4de9866be783",
   "metadata": {},
   "source": [
    "### 5) How do we calculate the slope m in Simple Linear Regression?\n",
    "The slope \\( m \\) can be calculated using the following formula:\n",
    "\n",
    "$$ m = \\frac{n(\\sum XY) - (\\sum X)(\\sum Y)}{n(\\sum X^2) - (\\sum X)^2} $$\n",
    "\n",
    "Where:\n",
    "- \\( n \\) is the number of data points,\n",
    "- \\( X \\) and \\( Y \\) are the independent and dependent variables,\n",
    "- \\( \\sum XY \\), \\( \\sum X \\), and \\( \\sum Y \\) are the sums of the products, \\( X \\), and \\( Y \\), respectively.\n",
    "\n",
    "This formula is derived from minimizing the sum of squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47b230-4b82-49c9-98f3-2b4b96ad3bff",
   "metadata": {},
   "source": [
    "### 6) What is the purpose of the least squares method in Simple Linear Regression?\n",
    "The least squares method is used to find the best-fitting line by minimizing the sum of squared residuals (errors) between the observed values and the predicted values. In essence, it ensures that the regression line is as close as possible to all the data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc18061-691c-4a09-a7cc-7cb57b5ae3e6",
   "metadata": {},
   "source": [
    "### 7) How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "The coefficient of determination, denoted as \\( R^2 \\), measures the proportion of the variance in the dependent variable \\( Y \\) that is predictable from the independent variable \\( X \\).\n",
    "\n",
    "- \\( R^2 \\) ranges from 0 to 1:\n",
    "  - \\( R^2 = 1 \\) means that the regression line perfectly explains the variation in \\( Y \\).\n",
    "  - \\( R^2 = 0 \\) means that the model does not explain any of the variation in \\( Y \\).\n",
    "  \n",
    "In general, a higher \\( R^2 \\) value indicates a better fit of the model to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1889-bc22-4683-b497-373c94d3758d",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "### 8) What is Multiple Linear Regression?\n",
    "Multiple Linear Regression is an extension of Simple Linear Regression that models the relationship between two or more independent variables and a dependent variable. The equation for multiple linear regression is:\n",
    "\n",
    "$$ Y = m_1X_1 + m_2X_2 + \\dots + m_nX_n + c $$\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) is the dependent variable,\n",
    "- \\( X_1, X_2, \\dots, X_n \\) are the independent variables,\n",
    "- \\( m_1, m_2, \\dots, m_n \\) are the coefficients for the independent variables,\n",
    "- \\( c \\) is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f365fd-f7fb-4be7-ac62-88904205e562",
   "metadata": {},
   "source": [
    "### 9) What is the main difference between Simple and Multiple Linear Regression?\n",
    "The main difference is in the number of independent variables:\n",
    "- **Simple Linear Regression** involves only one independent variable.\n",
    "- **Multiple Linear Regression** involves two or more independent variables.\n",
    "\n",
    "Multiple Linear Regression allows for more complex modeling of relationships, especially when the dependent variable is influenced by several factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3b98b-12f2-4d9b-a685-c1a7f5437152",
   "metadata": {},
   "source": [
    "### 10) What are the key assumptions of Multiple Linear Regression?\n",
    "The key assumptions for Multiple Linear Regression are similar to those of Simple Linear Regression:\n",
    "1. **Linearity**: The relationship between the dependent and independent variables is linear.\n",
    "2. **Independence**: The observations are independent of each other.\n",
    "3. **Homoscedasticity**: The variance of errors is constant across all levels of the independent variables.\n",
    "4. **Normality**: The residuals (errors) of the model are normally distributed.\n",
    "5. **No multicollinearity**: The independent variables should not be highly correlated with each other. If they are, it can cause issues with the model's stability and interpretability.\n",
    "6. **No autocorrelation**: The residuals should not be correlated with each other over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68369759-53db-4bd5-8602-e14eaa603408",
   "metadata": {},
   "source": [
    "# Advanced Concepts in Multiple Linear Regression\n",
    "\n",
    "### 11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "**Heteroscedasticity** refers to the situation where the variance of the errors (residuals) is not constant across all levels of the independent variables. In other words, as the value of the independent variable changes, the spread of the residuals also changes.\n",
    "\n",
    "#### Impact on Regression Model:\n",
    "- **Bias in Standard Errors**: Heteroscedasticity can lead to biased estimates of standard errors, which can affect hypothesis testing (e.g., t-tests). This means that we might incorrectly reject or fail to reject the null hypothesis.\n",
    "- **Inefficient Estimates**: The regression coefficients might still be unbiased, but they will not be efficient (i.e., they won’t have the minimum possible variance).\n",
    "- **Invalid Inference**: The significance tests (such as p-values) might not be valid, leading to incorrect conclusions.\n",
    "  \n",
    "#### How to Detect Heteroscedasticity:\n",
    "- **Residual Plot**: A plot of residuals versus fitted values. If there is a pattern (e.g., funnel-shaped spread), it may indicate heteroscedasticity.\n",
    "\n",
    "#### How to Address Heteroscedasticity:\n",
    "- **Transform the dependent variable** (e.g., apply a log transformation to reduce variance).\n",
    "- **Use weighted least squares** (WLS) regression.\n",
    "- **Robust standard errors**: Adjust the standard errors to account for heteroscedasticity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8273e-6b54-4474-adb4-b7e8a9c43478",
   "metadata": {},
   "source": [
    "### 12) How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "**Multicollinearity** occurs when two or more independent variables in a regression model are highly correlated with each other. This makes it difficult to isolate the effect of each independent variable on the dependent variable.\n",
    "\n",
    "#### Effects of Multicollinearity:\n",
    "- **Inflated Standard Errors**: Multicollinearity can lead to large standard errors for the regression coefficients, making it harder to determine which variables are statistically significant.\n",
    "- **Unstable Coefficient Estimates**: The coefficients may become highly sensitive to small changes in the data, leading to unreliable predictions.\n",
    "\n",
    "#### Ways to Address Multicollinearity:\n",
    "1. **Remove one of the correlated variables**: If two variables are highly correlated, you can remove one to reduce redundancy.\n",
    "2. **Combine the correlated variables**: Create a new variable that combines the correlated variables (e.g., by averaging them or using principal component analysis).\n",
    "3. **Apply Ridge or Lasso Regression**: These techniques apply a penalty to large coefficients, which can help reduce multicollinearity by shrinking them towards zero.\n",
    "4. **Use Variance Inflation Factor (VIF)**: Calculate VIF for each predictor. A high VIF (greater than 10) indicates problematic multicollinearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70982e26-4261-433a-ab36-59d90fd30a98",
   "metadata": {},
   "source": [
    "### 13) What are some common techniques for transforming categorical variables for use in regression models?\n",
    "Categorical variables cannot be directly used in regression models because they are not numerical. Several methods can be used to transform categorical variables into a form that regression models can process:\n",
    "\n",
    "#### Common Techniques:\n",
    "1. **One-Hot Encoding**: \n",
    "   - Converts each category into a separate binary (0 or 1) variable. \n",
    "   - For example, a \"color\" variable with values \"Red,\" \"Blue,\" and \"Green\" will be transformed into three binary variables: \"Color_Red,\" \"Color_Blue,\" and \"Color_Green.\"\n",
    "\n",
    "2. **Label Encoding**: \n",
    "   - Assigns each category a unique integer. For example, \"Red\" might be encoded as 0, \"Blue\" as 1, and \"Green\" as 2.\n",
    "   - This method is usually less preferred for nominal data (where there is no inherent order) because it can imply an ordinal relationship that doesn't exist.\n",
    "\n",
    "3. **Ordinal Encoding**: \n",
    "   - Similar to label encoding, but used when the categories have a meaningful order, such as \"Low,\" \"Medium,\" and \"High.\"\n",
    "\n",
    "4. **Binary Encoding**: \n",
    "   - Converts each category into binary digits. This method is often used when there are a large number of categories, as it is more compact than one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee00fb-b39f-49a3-a037-95030759c548",
   "metadata": {},
   "source": [
    "### 14) What is the role of interaction terms in Multiple Linear Regression?\n",
    "**Interaction terms** are used in multiple linear regression to model the combined effect of two or more independent variables on the dependent variable. Instead of treating the effect of each variable individually, interaction terms account for the possibility that the effect of one variable may depend on the value of another.\n",
    "\n",
    "For example, if you are modeling sales (\\( Y \\)) based on both advertising spend (\\( X_1 \\)) and price (\\( X_2 \\)), an interaction term \\( X_1 \\times X_2 \\) would allow the model to account for the idea that the effect of advertising might depend on the price level.\n",
    "\n",
    "#### Why Use Interaction Terms?\n",
    "- **Capturing Synergies**: They allow you to model complex relationships where the combined effect of two predictors is different from the sum of their individual effects.\n",
    "- **Improved Model Fit**: Including relevant interaction terms can lead to a better model fit and more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342504df-c63a-4b31-8e90-0d55f912545d",
   "metadata": {},
   "source": [
    "### 15) How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "The **intercept** (\\( c \\)) represents the expected value of the dependent variable \\( Y \\) when all independent variables are equal to zero.\n",
    "\n",
    "#### In Simple Linear Regression:\n",
    "- The intercept represents the value of \\( Y \\) when the single independent variable \\( X \\) is 0. This is often meaningful if \\( X = 0 \\) is a valid condition (e.g., predicting weight at age 0).\n",
    "- Example: If \\( Y \\) represents \"height\" and \\( X \\) represents \"age,\" the intercept would represent the expected height when age is 0.\n",
    "\n",
    "#### In Multiple Linear Regression:\n",
    "- The intercept represents the expected value of \\( Y \\) when **all** independent variables are equal to zero. This interpretation can sometimes be less meaningful if zero is not a valid value for all predictors.\n",
    "- Example: In a model predicting \"salary\" based on \"years of experience\" and \"education level,\" the intercept would represent the expected salary when both \"years of experience\" and \"education level\" are zero, which might not make sense in a real-world context.\n",
    "\n",
    "In multiple regression, the intercept is often considered less interpretable unless the zero values of all predictors are realistic and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558714e7-023d-4982-8300-595fe3adba41",
   "metadata": {},
   "source": [
    "### 16) What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\n",
    "In regression analysis, the **slope** is a key coefficient that represents the relationship between the independent variable (\\( X \\)) and the dependent variable (\\( Y \\)). Specifically, the slope (\\( m \\)) indicates the amount of change in \\( Y \\) for a one-unit change in \\( X \\).\n",
    "\n",
    "#### Significance of the Slope:\n",
    "- **Magnitude of Change**: The slope tells us how sensitive the dependent variable is to changes in the independent variable. A larger slope means a greater change in \\( Y \\) for a given change in \\( X \\).\n",
    "- **Direction of Relationship**: The sign of the slope (positive or negative) indicates the direction of the relationship. A positive slope means that as \\( X \\) increases, \\( Y \\) also increases (direct relationship), while a negative slope means that as \\( X \\) increases, \\( Y \\) decreases (inverse relationship).\n",
    "\n",
    "#### Impact on Predictions:\n",
    "- When making predictions, the slope is used to determine how the dependent variable will change based on new input values of the independent variable. For example, if the slope is 3, then for every increase of 1 unit in \\( X \\), \\( Y \\) will increase by 3 units.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dab736-1ad9-49b7-9d54-115e06646d15",
   "metadata": {},
   "source": [
    "### 17) How does the intercept in a regression model provide context for the relationship between variables?\n",
    "\n",
    "The **intercept** (\\( c \\)) in a regression model represents the predicted value of the dependent variable (\\( Y \\)) when the independent variable (\\( X \\)) is zero. It essentially provides the baseline level of \\( Y \\) when \\( X \\) does not have any influence.\n",
    "\n",
    "#### Significance of the Intercept:\n",
    "- **Context of the Relationship**: The intercept gives us the starting point for the regression line (or curve). It is the point where the line crosses the Y-axis. If the independent variable cannot logically be zero, the intercept may not have a meaningful interpretation, but it still serves as a part of the equation.\n",
    "- **Influence of Initial Conditions**: In real-world problems, the intercept can reflect underlying conditions, such as a starting amount or a baseline state. For example, in predicting salary based on experience, the intercept could represent the salary at zero years of experience, which may indicate an entry-level position's base salary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99232419-374c-4329-8040-ffd76178ac0b",
   "metadata": {},
   "source": [
    "### 18) What are the limitations of using R² as a sole measure of model performance?\n",
    "\n",
    "While the **coefficient of determination (R²)** is a commonly used measure of model performance, it has several limitations when used in isolation.\n",
    "\n",
    "#### Limitations:\n",
    "1. **Does Not Indicate Causality**:\n",
    "   - A high R² value does not imply that the independent variable causes the changes in the dependent variable; it simply reflects the degree to which the model fits the data.\n",
    "  \n",
    "2. **Does Not Account for Overfitting**:\n",
    "   - R² always increases with the addition of more predictors, even if the new predictors are not meaningful. This can lead to overfitting, where the model fits the training data very well but performs poorly on unseen data. This is why **adjusted R²** is often used, as it accounts for the number of predictors.\n",
    "\n",
    "3. **Insensitive to Non-linear Relationships**:\n",
    "   - R² assumes a linear relationship between variables. If the data has a non-linear relationship, a linear regression model may give a low R² value, even though the model captures a significant portion of the variance. In such cases, non-linear models or polynomial regression might be more appropriate.\n",
    "\n",
    "4. **Sensitive to Outliers**:\n",
    "   - R² can be highly sensitive to outliers, which can skew the model’s performance. Even a few extreme data points can inflate or deflate the R² value, giving a misleading impression of model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ac2a0-8248-46a8-a610-174757579f6e",
   "metadata": {},
   "source": [
    "### 19) How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "The **standard error** (SE) of a regression coefficient measures the variability or uncertainty of the estimated coefficient. A larger standard error indicates more uncertainty in the estimate of the coefficient, meaning that the coefficient is less precise.\n",
    "\n",
    "#### Interpretation of a Large Standard Error:\n",
    "1. **Low Confidence in Coefficient Estimate**:\n",
    "   - If the standard error is large, it means the coefficient estimate has high variability and may not be a reliable indicator of the relationship between the predictor and the response variable.\n",
    "   \n",
    "2. **Potential for Non-Significance**:\n",
    "   - A large standard error often indicates that the coefficient is not significantly different from zero. In hypothesis testing, this would lead to a high p-value, suggesting that the predictor is not statistically significant.\n",
    "\n",
    "3. **Possible Multicollinearity**:\n",
    "   - A large standard error can also be an indication of **multicollinearity**—when independent variables are highly correlated with each other. Multicollinearity makes it difficult to isolate the individual effects of each predictor, leading to inflated standard errors for the coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f721d-9157-4210-ac33-ab459700789a",
   "metadata": {},
   "source": [
    "### 20) How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\n",
    "**Heteroscedasticity** refers to the condition in which the variability of the residuals (errors) is not constant across all levels of the independent variable. In simpler terms, the spread of the residuals increases or decreases as the predicted values change. This violates one of the key assumptions of linear regression, which is that the residuals should have constant variance (homoscedasticity).\n",
    "\n",
    "#### Identifying Heteroscedasticity:\n",
    "Heteroscedasticity can be identified through **residual plots**. Here’s what to look for:\n",
    "- **Residual vs. Fitted Plot**: A residual plot plots the residuals (the differences between observed and predicted values) on the vertical axis against the predicted values (fitted values) on the horizontal axis. In the case of heteroscedasticity, the residuals will fan out or contract as the predicted values increase or decrease. For example, if the spread of residuals increases as the predicted values increase, this indicates heteroscedasticity.\n",
    "- **Patterned Residuals**: If you notice a pattern or a funnel shape in the residual plot (where the spread of the residuals increases or decreases with the fitted values), it suggests that the assumption of constant variance is violated.\n",
    "\n",
    "#### Why It’s Important to Address Heteroscedasticity:\n",
    "1. **Impact on Validity of Statistical Tests**:\n",
    "   - When heteroscedasticity is present, the results of statistical tests (like t-tests for individual regression coefficients) can be unreliable. The p-values may be biased, leading to incorrect conclusions about the significance of predictors.\n",
    "   \n",
    "2. **Inefficiency of Coefficients**:\n",
    "   - Heteroscedasticity reduces the efficiency of the OLS (Ordinary Least Squares) estimates. The coefficients themselves may still be unbiased, but they will no longer be the most efficient (i.e., they won’t have the smallest possible standard errors), leading to less precise estimates.\n",
    "\n",
    "3. **Unreliable Predictions**:\n",
    "   - Since heteroscedasticity affects the variance of the error terms, it can make predictions less reliable, especially for values where the residual variance is large.\n",
    "\n",
    "#### How to Address Heteroscedasticity:\n",
    "- **Transformations**: Transforming the dependent variable (e.g., applying a log transformation) can sometimes help stabilize variance.\n",
    "- **Weighted Least Squares (WLS)**: In the presence of heteroscedasticity, you might use WLS regression, which gives different weights to different data points based on their variance.\n",
    "- **Robust Standard Errors**: Using robust standard errors can help adjust the estimated coefficients' standard errors, making them more reliable even when heteroscedasticity is present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f8b52-21f4-45db-84fb-9464b2febbeb",
   "metadata": {},
   "source": [
    "### 21) What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "If a model has a **high R²** but a **low adjusted R²**, it suggests that while the model explains a large portion of the variance in the dependent variable, the inclusion of additional independent variables might not be improving the model in a meaningful way.\n",
    "\n",
    "#### Interpretation:\n",
    "- **High R²**: The model fits the data well, but this might be due to overfitting, especially if many predictors are included.\n",
    "- **Low adjusted R²**: The model is penalizing the inclusion of too many predictors, and the added variables may not contribute to explaining the variance in a statistically meaningful way.\n",
    "\n",
    "This discrepancy suggests that the model may be too complex and might need simplification or the removal of non-significant predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbbc73f-1219-49af-a90e-741a02f82206",
   "metadata": {},
   "source": [
    "### 22) Why is it important to scale variables in Multiple Linear Regression?\n",
    "Scaling variables in **Multiple Linear Regression** ensures that all variables contribute equally to the model and that the coefficients are on comparable scales.\n",
    "\n",
    "#### Importance:\n",
    "1. **Equal Contribution**: Variables with larger ranges or higher magnitudes can disproportionately influence the regression model. Scaling ensures that each variable has a similar impact on the outcome.\n",
    "2. **Interpretation of Coefficients**: When predictors are on different scales (e.g., one variable in meters and another in kilograms), their coefficients may be difficult to compare. Scaling makes the coefficients more interpretable.\n",
    "3. **Improved Model Performance**: Some machine learning algorithms, especially those based on gradient descent, converge faster when variables are scaled. Scaling ensures that all variables are treated equally during optimization.\n",
    "\n",
    "#### Techniques:\n",
    "- **Standardization (Z-score Scaling)**: Subtracting the mean and dividing by the standard deviation.\n",
    "- **Min-Max Scaling**: Scaling the variables to a fixed range, such as [0, 1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b4d6b-3da6-4cab-b094-90506ce021fe",
   "metadata": {},
   "source": [
    "# Polynomial Regression Concepts\n",
    "\n",
    "### 23) What is Polynomial Regression?\n",
    "**Polynomial regression** is a type of regression analysis in which the relationship between the independent variable \\( X \\) and the dependent variable \\( Y \\) is modeled as an \\( n \\)-th degree polynomial. Instead of fitting a straight line (as in simple linear regression), polynomial regression fits a curve to the data. \n",
    "\n",
    "The general form of a polynomial regression equation is:\n",
    "\\[\n",
    "Y = c + m_1 X + m_2 X^2 + m_3 X^3 + \\dots + m_n X^n\n",
    "\\]\n",
    "Where:\n",
    "- \\( Y \\) is the dependent variable,\n",
    "- \\( X \\) is the independent variable,\n",
    "- \\( m_1, m_2, \\dots, m_n \\) are the coefficients that need to be estimated,\n",
    "- \\( c \\) is the intercept, and\n",
    "- \\( n \\) is the degree of the polynomial.\n",
    "\n",
    "#### Key Features:\n",
    "- Polynomial regression allows for modeling **non-linear** relationships by using higher-degree powers of the independent variable.\n",
    "- By adding higher powers of \\( X \\), polynomial regression can fit curves that have turns or bends, offering greater flexibility in modeling complex data patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bb008-97dd-4051-bc03-dc6bb143bd75",
   "metadata": {},
   "source": [
    "### 24) How does Polynomial Regression differ from Linear Regression?\n",
    "**Linear regression** and **polynomial regression** both model the relationship between independent and dependent variables, but they differ in the form of the equation used.\n",
    "\n",
    "#### Key Differences:\n",
    "1. **Equation Form**:\n",
    "   - **Linear Regression**: The relationship is modeled as a straight line (first-degree polynomial).\n",
    "   \\[\n",
    "   Y = c + m_1 X\n",
    "   \\]\n",
    "   - **Polynomial Regression**: The relationship is modeled as a polynomial, which can have higher-degree terms.\n",
    "   \\[\n",
    "   Y = c + m_1 X + m_2 X^2 + m_3 X^3 + \\dots\n",
    "   \\]\n",
    "\n",
    "2. **Linearity**:\n",
    "   - **Linear Regression** assumes a **linear relationship** between the independent and dependent variables. This means that the change in \\( Y \\) is proportional to the change in \\( X \\), and it can be represented by a straight line.\n",
    "   - **Polynomial Regression** allows for a **non-linear relationship**, where the change in \\( Y \\) is not proportional to the change in \\( X \\), and can be represented by a curve. This is useful when the data shows trends that change direction (e.g., concave or convex curves).\n",
    "\n",
    "3. **Flexibility**:\n",
    "   - **Linear Regression** is limited to fitting straight lines to data, making it less flexible in capturing complex, non-linear trends.\n",
    "   - **Polynomial Regression** can capture more complex relationships in the data by including higher-degree polynomial terms. This allows it to fit curves that can have bends or turns.\n",
    "\n",
    "4. **Complexity and Overfitting**:\n",
    "   - **Linear Regression** is relatively simple, and it typically does not overfit unless the data is particularly noisy or if there are outliers.\n",
    "   - **Polynomial Regression** can become complex as the degree of the polynomial increases. While it allows for more flexible fits, it also increases the risk of **overfitting**. As the degree increases, the model might fit the training data perfectly but fail to generalize well to unseen data.\n",
    "\n",
    "#### Visual Example:\n",
    "- In linear regression, the data points are fitted with a straight line, while in polynomial regression, the line is curved, providing a better fit for data with non-linear patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5157bf-1a64-4544-a6b4-1eb05112c9e8",
   "metadata": {},
   "source": [
    "### 25) When is Polynomial Regression used?\n",
    "Polynomial regression is used when the relationship between the independent and dependent variables is not linear, but still follows a predictable pattern. It is commonly used in situations where a straight line is not a good fit for the data, but a curve would better represent the underlying trend.\n",
    "\n",
    "#### Common Scenarios for Using Polynomial Regression:\n",
    "1. **Data with Curved Relationships**:\n",
    "   - When the data exhibits a curve, such as quadratic or cubic behavior, polynomial regression can capture the bending or turning patterns, while linear regression would fail to fit it accurately.\n",
    "   \n",
    "   Example: Modeling the relationship between the amount of time a person spends studying and their exam score, where the relationship might first rise steeply and then level off.\n",
    "\n",
    "2. **When Linear Models Fail to Fit**:\n",
    "   - If a scatter plot shows that the data is not well represented by a straight line, polynomial regression can be used to model the curve and capture the underlying trend more accurately.\n",
    "   \n",
    "   Example: Predicting the growth of a population or the effect of temperature on crop yield, where changes are not linear.\n",
    "\n",
    "3. **Complex Data Patterns**:\n",
    "   - In cases where there is an inflection point or a pattern with increasing or decreasing rates of change, polynomial regression is useful to model that complexity.\n",
    "\n",
    "   Example: Modeling the speed of a car as a function of time, where acceleration increases, and then decreases over time.\n",
    "\n",
    "#### Limitations:\n",
    "- **Overfitting**: As the degree of the polynomial increases, the model might overfit the training data, leading to poor generalization on new data. This is a major risk when using polynomial regression, so it's important to balance model complexity with the risk of overfitting.\n",
    "- **Interpretability**: Higher-degree polynomials may result in less interpretable models, as the relationship between \\( X \\) and \\( Y \\) becomes more complex and harder to explain intuitively.\n",
    "\n",
    "#### Conclusion:\n",
    "Polynomial regression is a valuable tool when the data shows a clear non-linear pattern. However, care should be taken to avoid overfitting by carefully selecting the degree of the polynomial and validating the model on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4fc8ad-a45f-4774-a834-a96f6a31ac77",
   "metadata": {},
   "source": [
    "# Polynomial Regression - Further Insights\n",
    "\n",
    "### 26) What is the general equation for polynomial regression?\n",
    "The general equation for **polynomial regression** is an extension of linear regression, where the relationship between the independent variable \\( X \\) and the dependent variable \\( Y \\) is modeled as a polynomial of degree \\( n \\). The general form of the polynomial regression equation is:\n",
    "\n",
    "\\[\n",
    "Y = c + m_1 X + m_2 X^2 + m_3 X^3 + \\dots + m_n X^n\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) is the dependent variable (the value we are trying to predict),\n",
    "- \\( c \\) is the intercept,\n",
    "- \\( m_1, m_2, \\dots, m_n \\) are the coefficients that represent the weight of each term,\n",
    "- \\( X \\) is the independent variable,\n",
    "- \\( n \\) is the degree of the polynomial.\n",
    "\n",
    "The higher the degree \\( n \\), the more flexible the curve, allowing it to fit more complex patterns in the data. However, as the degree increases, the model may become prone to overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a33b6-1608-4599-913d-4bddb13eefd5",
   "metadata": {},
   "source": [
    "### 27) Can polynomial regression be applied to multiple variables?\n",
    "Yes, **polynomial regression** can be applied to multiple variables, which is known as **multiple polynomial regression**. This is an extension of simple polynomial regression where more than one independent variable is involved.\n",
    "\n",
    "The general equation for **multiple polynomial regression** (with two independent variables \\( X_1 \\) and \\( X_2 \\)) is:\n",
    "\n",
    "\\[\n",
    "Y = c + m_1 X_1 + m_2 X_1^2 + m_3 X_2 + m_4 X_2^2 + \\dots + m_n X_1^k X_2^l + \\dots\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( X_1 \\) and \\( X_2 \\) are the independent variables,\n",
    "- \\( m_1, m_2, \\dots, m_n \\) are the coefficients for the terms,\n",
    "- \\( k, l, \\dots \\) are the exponents of the variables, determining the degree of the terms.\n",
    "\n",
    "In this case, polynomial regression involves not only the individual powers of each variable but also **interaction terms** between variables (e.g., \\( X_1 X_2 \\), \\( X_1^2 X_2 \\)) to capture complex relationships between the predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84448302-bb4f-41d0-8014-320948d826bd",
   "metadata": {},
   "source": [
    "### 28) What are the limitations of polynomial regression?\n",
    "While **polynomial regression** is a powerful tool for modeling non-linear relationships, it does come with several limitations:\n",
    "\n",
    "#### Limitations:\n",
    "1. **Overfitting**:\n",
    "   - As the degree of the polynomial increases, the model becomes more flexible, which can lead to **overfitting**. The model might fit the training data perfectly but perform poorly on unseen data because it starts capturing noise rather than the underlying trend.\n",
    "\n",
    "2. **Extrapolation Issues**:\n",
    "   - Polynomial regression models, especially higher-degree ones, can behave unpredictably outside the range of the training data. This means that predictions made for values of \\( X \\) far beyond the training data might be wildly inaccurate.\n",
    "\n",
    "3. **Multicollinearity**:\n",
    "   - Higher-degree polynomials can introduce multicollinearity, where the predictors (e.g., \\( X, X^2, X^3 \\)) are highly correlated with each other, making it difficult to interpret the model and causing instability in the coefficient estimates.\n",
    "\n",
    "4. **Interpretability**:\n",
    "   - As the degree of the polynomial increases, the model becomes increasingly complex, making it harder to interpret the relationship between the independent and dependent variables.\n",
    "\n",
    "5. **Computational Complexity**:\n",
    "   - Higher-degree polynomials can increase the computational complexity, especially with large datasets, which might make training the model slower and more resource-intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12458c7a-fb2d-4a33-81b9-0e88ca035804",
   "metadata": {},
   "source": [
    "### 29) What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "When selecting the degree of a polynomial for regression, it's important to evaluate the **model fit** to ensure it balances complexity and predictive power. Some methods to evaluate model fit include:\n",
    "\n",
    "#### 1. **Cross-validation**:\n",
    "   - Cross-validation, particularly **k-fold cross-validation**, helps assess the generalizability of the model. By splitting the data into multiple folds and training the model on each fold, we can ensure that the model's performance is stable and not due to overfitting.\n",
    "\n",
    "#### 2. **Adjusted R²**:\n",
    "   - The **adjusted R²** metric penalizes the addition of unnecessary variables (or higher-degree terms in the polynomial) and gives a more accurate picture of how well the model fits the data. Unlike regular R², adjusted R² accounts for the number of predictors, making it useful when selecting the degree of the polynomial.\n",
    "\n",
    "#### 3. **Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)**:\n",
    "   - **MSE** or **RMSE** can be used to evaluate the residual errors of the model. A lower MSE or RMSE indicates better model fit. You can compare the errors for models with different polynomial degrees and choose the one with the lowest error.\n",
    "\n",
    "#### 4. **Akaike Information Criterion (AIC)**:\n",
    "   - The **AIC** is another metric that helps select a good model by balancing the goodness of fit and model complexity. It penalizes models with more parameters (higher degree), helping to avoid overfitting.\n",
    "\n",
    "#### 5. **Visual Inspection**:\n",
    "   - Plotting the **residuals** (the differences between the actual and predicted values) is an important method to evaluate fit. A good model will have residuals randomly scattered around zero, without any clear patterns. Additionally, plotting the model's predictions against the true values (via a scatter plot) helps assess whether the curve is fitting the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb5e7e-c15d-4e94-8db1-4da8c617a563",
   "metadata": {},
   "source": [
    "### 30) Why is visualization important in polynomial regression?\n",
    "**Visualization** plays a crucial role in **polynomial regression** for the following reasons:\n",
    "\n",
    "1. **Model Behavior**:\n",
    "   - Visualization allows you to see how well the polynomial curve fits the data. You can plot the observed values versus the predicted values to visually assess whether the polynomial regression model captures the underlying trend.\n",
    "\n",
    "2. **Detecting Overfitting**:\n",
    "   - By visualizing the fit of the model with varying degrees of polynomials, you can detect if the model is overfitting (e.g., the curve becomes excessively wiggly with a higher polynomial degree).\n",
    "\n",
    "3. **Identifying Patterns**:\n",
    "   - Plotting the residuals helps identify issues like non-random errors, patterns in the data, or signs of heteroscedasticity. It gives insight into whether the model is appropriately capturing the data's structure.\n",
    "\n",
    "4. **Better Model Selection**:\n",
    "   - Visualization of the data and the model fit allows you to better judge the best polynomial degree. By plotting models with different polynomial degrees, you can decide which degree provides the best trade-off between fit and complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd428a74-6729-4c6b-ac63-ccf8315167a8",
   "metadata": {},
   "source": [
    "### 31) How is polynomial regression implemented in Python?\n",
    "Polynomial regression in Python can be implemented using libraries like **scikit-learn** and **numpy**. Here's a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d795683-5b00-4e29-bf48-485497538959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQjElEQVR4nO3dd1yVdf/H8dcBFFyguJDAmSvNnaZm7pwpuUeK5d1w5cw777tSK2/LTL27czXV0myJ5s6tOdLcWpoarhw5EhAVFa7fH98f6BFQMOA6B97Px+M8PNd1rnP4XFwob7/rcliWZSEiIiLihjzsLkBERETkfinIiIiIiNtSkBERERG3pSAjIiIibktBRkRERNyWgoyIiIi4LQUZERERcVsKMiIiIuK2FGRERETEbSnISKbXoEEDGjRoYHcZaWLGjBk4HA6OHj2a6vf26tWL4sWLp3lNmVXx4sXp1auXbV9/3LhxlCtXjri4ONtqcHevvPIKtWrVsrsMSWcKMuJy4n9Zxz98fHwoU6YM/fv35+zZs3aXl+k1aNDA6fufI0cOKlWqxKRJk/RLNYNERkbyzjvv8M9//hMPj1v/TN9+Xby8vPD396d69eoMHDiQX375xcaKM86JEycYPXo0NWvWJF++fBQoUIAGDRqwcuXKRMcOGjSI3bt38/3339tQqWQUL7sLEEnOG2+8QYkSJbh27Ro//vgjU6dOZcmSJezbt4+cOXPaXZ4tevToQZcuXfD29k7XrxMUFMTYsWMBOH/+PHPmzGHw4MGcO3eOMWPGpOvXdhUHDx50ChEZ6dNPP+XmzZt07do10WtNmzalZ8+eWJZFREQEu3fvZubMmUyZMoV33nmHIUOG2FBxxlmwYAHvvPMOISEhhIaGcvPmTWbNmkXTpk359NNPeeaZZxKODQgIoG3btowfP542bdrYWLWkK0vExXz22WcWYG3bts1p/5AhQyzAmjNnTqo+r379+lb9+vXTsEL3FBoaahUrVuyex9WvX9+qUKGC076rV69axYoVs/LkyWPdvHkznSpM2tWrV63Y2NgM/Zp2q1SpkvX0008n2g9Y/fr1S7T//PnzVu3atS3AWrx4cUaU6OTy5csZ9rX27dtnnTt3zmnftWvXrHLlyllBQUGJjv/2228th8NhHTlyJKNKlAymriVxG40aNQIgPDwcgJs3b/Lmm29SqlQpvL29KV68OP/617+IiYlJ9jMuX75Mrly5GDhwYKLXTp48iaenZ0JLRHwX18aNGxkyZAgFCxYkV65cPPXUU5w7dy7R+6dMmUKFChXw9vYmMDCQfv36cenSJadjGjRoQMWKFdmzZw/169cnZ86cPPjgg3z77bcArFu3jlq1apEjRw7Kli2bqLk8qTEyCxYsoFWrVgQGBuLt7U2pUqV48803iY2Nvfc3NYV8fHx45JFHiIqK4s8//3R67YsvvqB69erkyJEDf39/unTpwokTJxJ9xuTJkylZsiQ5cuSgZs2abNiwIdH4pbVr1+JwOJg7dy6vvvoqDzzwADlz5iQyMhKAn376iebNm+Pn50fOnDmpX78+GzdudPo6UVFRDBo0iOLFi+Pt7U2hQoVo2rQpO3bsSDjm0KFDtG/fnoCAAHx8fAgKCqJLly5EREQkHJPUGJnff/+djh074u/vT86cOXn00UdZvHix0zHx5/D1118zZswYgoKC8PHxoXHjxhw+fPie3+vw8HD27NlDkyZN7nlsvPz58zN37ly8vLwStZjFxMQwcuRIHnzwQby9vQkODmb48OGJ/p5cvXqVl156iQIFCpAnTx7atGnDH3/8gcPhYNSoUQnHjRo1CofDwS+//EK3bt3Ily8fjz32WMLrKf15SMm1TEqFChUoUKCA0z5vb29atmzJyZMniYqKcnot/vu4YMGCe362uCcFGXEbR44cAcw/2gD/+Mc/eP3116lWrRoTJ06kfv36jB07li5duiT7Gblz5+app57iq6++SvSL/ssvv8SyLLp37+60f8CAAezevZuRI0fSp08fFi5cSP/+/Z2OGTVqFP369SMwMJD33nuP9u3bM336dJ544glu3LjhdOxff/1F69atqVWrFuPGjcPb25suXbrw1Vdf0aVLF1q2bMnbb79NdHQ0HTp0SPQP851mzJhB7ty5GTJkCP/973+pXr06r7/+Oq+88srdv6GpdPToURwOB3nz5k3YN2bMGHr27Enp0qWZMGECgwYNYtWqVTz++ONOIW7q1Kn079+foKAgxo0bR7169QgJCeHkyZNJfq0333yTxYsXM2zYMP7zn/+QPXt2Vq9ezeOPP05kZCQjR47kP//5D5cuXaJRo0Zs3bo14b0vvvgiU6dOpX379kyZMoVhw4aRI0cOfv31VwCuX79Os2bN2LJlCwMGDGDy5Mk8//zz/P7774mC5+3Onj1LnTp1WL58OX379mXMmDFcu3aNNm3aEBYWluj4t99+m7CwMIYNG8aIESPYsmVLop+tpGzatAmAatWq3fPY2xUtWpT69euzZcuWhOAXFxdHmzZtGD9+PE8++ST/+9//CAkJYeLEiXTu3Nnp/b169eJ///sfLVu25J133iFHjhy0atUq2a/XsWNHrly5wn/+8x+ee+45IOU/Dym9lqlx5swZcubMmajb2c/Pj1KlSqUoJImbsrtJSORO8V1LK1eutM6dO2edOHHCmjt3rpU/f34rR44c1smTJ61du3ZZgPWPf/zD6b3Dhg2zAGv16tUJ++7sWlq+fLkFWEuXLnV6b6VKlZyOi6+jSZMmVlxcXML+wYMHW56entalS5csy7KsP//808qePbv1xBNPOHWBfPDBBxZgffrpp061cEf32IEDByzA8vDwsLZs2ZKozs8++yxRTeHh4Qn7rly5kuh7+MILL1g5c+a0rl27lrAvNV1L5cqVs86dO2edO3fOOnDggPXyyy9bgNWqVauE444ePWp5enpaY8aMcXr/3r17LS8vr4T9MTExVv78+a1HHnnEunHjRsJxM2bMsACn7/maNWsswCpZsqTTecXFxVmlS5e2mjVr5nQtrly5YpUoUcJq2rRpwj4/P78ku1/i7dy50wKsb7755q7fh2LFilmhoaEJ24MGDbIAa8OGDQn7oqKirBIlSljFixdPuPbx51C+fHkrJiYm4dj//ve/FmDt3bv3rl/31VdftQArKioq0Wsk07UUb+DAgRZg7d6927Isy/r8888tDw8Pp5oty7KmTZtmAdbGjRsty7Ks7du3W4A1aNAgp+N69eplAdbIkSMT9o0cOdICrK5duzodm9Kfh9Rcy5Q6dOiQ5ePjY/Xo0SPJ15944gmrfPnyqf5ccQ9qkRGX1aRJEwoWLEhwcDBdunQhd+7chIWF8cADD7BkyRKARAMbhw4dCpCouf/Ozw0MDGT27NkJ+/bt28eePXt4+umnEx3//PPP43A4Erbr1atHbGwsx44dA2DlypVcv36dQYMGOQ0Ofe655/D19U1US+7cuZ1ajcqWLUvevHkpX76801TR+Oe///57sucCkCNHjoTnUVFRnD9/nnr16nHlyhUOHDhw1/cm58CBAxQsWJCCBQtSrlw53n33Xdq0acOMGTMSjpk3bx5xcXF06tSJ8+fPJzwCAgIoXbo0a9asAeDnn3/mwoULPPfcc3h53Zpf0L17d/Lly5fk1w8NDXU6r127dnHo0CG6devGhQsXEr5WdHQ0jRs3Zv369QkzqvLmzctPP/3EqVOnkvxsPz8/AJYvX86VK1dS/D1ZsmQJNWvWdOpGyZ07N88//zxHjx5NNGvomWeeIXv27Anb9erVA+59PS9cuICXlxe5c+dOcW231wMktOJ98803lC9fnnLlyjldo/hu2vhrtGzZMgD69u3r9HkDBgxI9mu9+OKLTtsp/XlIzbVMiStXrtCxY0dy5MjB22+/neQx+fLl4/z58yn+THEvmrUkLmvy5MmUKVMGLy8vChcuTNmyZROCwrFjx/Dw8ODBBx90ek9AQAB58+ZNCBlJ8fDwoHv37kydOpUrV66QM2dOZs+ejY+PDx07dkx0fNGiRZ2243/5/vXXXwm1gAkkt8uePTslS5ZMVEtQUJBTMALzyzU4ODjRvtu/TnL279/Pq6++yurVqxO6FOLdPuYjNYoXL85HH31EXFwcR44cYcyYMZw7dw4fH5+EYw4dOoRlWZQuXTrJz8iWLRtw6/tz57Xy8vJKdl2bEiVKOG0fOnQIMAEnOREREeTLl49x48YRGhpKcHAw1atXp2XLlvTs2ZOSJUsmfPaQIUOYMGECs2fPpl69erRp04ann3464XuelGPHjiW5Jkn58uUTXq9YsWLC/nv93KSHy5cvA5AnTx7AfN9+/fVXChYsmOTx8eOd4v8+3fl9v/Oa3S6pa5SSn4fUXMt7iY2NpUuXLvzyyy8sXbqUwMDAJI+zLCvR3znJPBRkxGXVrFmTGjVq3PWY+/3HqWfPnrz77rvMnz+frl27MmfOHFq3bp3kLzJPT88kP8OyrPv62sl93v18nUuXLlG/fn18fX154403KFWqFD4+PuzYsYN//vOf973uS65cuZwGm9atW5dq1arxr3/9i/fffx8w4y8cDgdLly5Nsvb7aVGId3trTPzXAnj33XepUqVKku+J/3qdOnWiXr16hIWF8cMPP/Duu+/yzjvvMG/ePFq0aAHAe++9R69evViwYAE//PADL730EmPHjmXLli0EBQXdd923u9+fm/z583Pz5k2ioqISAklK7du3D09Pz4SQERcXx8MPP8yECROSPP7O8JwaSV2jlPw8pOZa3stzzz3HokWLmD17dkIrU1L++uuvRAOEJfNQkBG3VKxYMeLi4jh06FDC/4jBDMi8dOkSxYoVu+v7K1asSNWqVZk9ezZBQUEcP36c//3vf/ddC5h1R+L/1w9mUGl4eHiqZp+k1tq1a7lw4QLz5s3j8ccfT9gfP7MrrVSqVImnn36a6dOnM2zYMIoWLUqpUqWwLIsSJUpQpkyZZN8b//05fPgwDRs2TNh/8+ZNjh49SqVKle759UuVKgWAr69vir6fRYoUoW/fvvTt25c///yTatWqMWbMmIQgA/Dwww/z8MMP8+qrr7Jp0ybq1q3LtGnTeOutt5I9j4MHDybaH999d6+fuZQqV64cYK5hSr438Y4fP866deuoXbt2QgAqVaoUu3fvpnHjxncN/fF/n8LDw51aVFIyyypeSn8eUnstk/Pyyy/z2WefMWnSpCTX27ldeHg4lStXvu+vJa5NY2TELbVs2RKASZMmOe2P/5/n3WZbxOvRowc//PADkyZNIn/+/E6/5FKjSZMmZM+enffff9/pf9uffPIJERERKarlfsX/z/f2r3v9+nWmTJmS5l9r+PDh3LhxI+F73K5dOzw9PRk9enSiVgbLsrhw4QIANWrUIH/+/Hz00UfcvHkz4ZjZs2enuJulevXqlCpVivHjxyd0n9wufjp8bGxsou60QoUKERgYmDDdODIy0qkOMKHGw8PjrlP3W7ZsydatW9m8eXPCvujoaD788EOKFy/OQw89lKJzuZfatWsDZmxRSl28eJGuXbsSGxvLv//974T9nTp14o8//uCjjz5K9J6rV68SHR0NQLNmzQAS/dykJtyn9Ochpdfybt59913Gjx/Pv/71rySXUrhdREQER44coU6dOik+F3EvapERt1S5cmVCQ0P58MMPE7pXtm7dysyZMwkJCXH6n39yunXrxvDhwwkLC6NPnz4JffipVbBgQUaMGMHo0aNp3rw5bdq04eDBg0yZMoVHHnkkyQHEaaVOnTrky5eP0NBQXnrpJRwOB59//vl9d3vdzUMPPUTLli35+OOPee211yhVqhRvvfUWI0aM4OjRo4SEhJAnTx7Cw8MJCwvj+eefZ9iwYWTPnp1Ro0YxYMAAGjVqRKdOnTh69CgzZsygVKlSKeoe9PDw4OOPP6ZFixZUqFCBZ555hgceeIA//viDNWvW4Ovry8KFC4mKiiIoKIgOHTpQuXJlcufOzcqVK9m2bRvvvfceYKb+9u/fn44dO1KmTBlu3rzJ559/jqenJ+3bt0+2hldeeYUvv/ySFi1a8NJLL+Hv78/MmTMJDw/nu+++S7NVgEuWLEnFihVZuXIlzz77bKLXf/vtN7744gssyyIyMpLdu3fzzTffcPnyZSZMmEDz5s0Tju3Rowdff/01L774ImvWrKFu3brExsZy4MABvv76a5YvX06NGjWoXr067du3Z9KkSVy4cIFHH32UdevW8dtvvwEp68JN6c9DSq9lcsLCwhg+fDilS5emfPnyfPHFF06vN23alMKFCydsr1y5EsuyaNu27T3PQdxUhs+TErmH5Fb2vdONGzes0aNHWyVKlLCyZctmBQcHWyNGjHCacmxZd1/Zt2XLlhZgbdq0KcV1xE+vXbNmjdP+Dz74wCpXrpyVLVs2q3DhwlafPn2sv/76K1Etd66aa1lmqu/tU5vjccd026SmX2/cuNF69NFHrRw5cliBgYHW8OHDE6Zu317j31nZN97atWsTTcf97rvvrMcee8zKlSuXlStXLqtcuXJWv379rIMHDzq99/3337eKFStmeXt7WzVr1rQ2btxoVa9e3WrevHnCMfHf2+SmRu/cudNq166dlT9/fsvb29sqVqyY1alTJ2vVqlWWZZmp3i+//LJVuXJlK0+ePFauXLmsypUrW1OmTEn4jN9//9169tlnrVKlSlk+Pj6Wv7+/1bBhQ2vlypVOX+vO6deWZVlHjhyxOnToYOXNm9fy8fGxatasaS1atMjpmOTOITw8PNF0+uRMmDDByp07d6Kp9UDCw8PDw8qbN69VtWpVa+DAgdb+/fuT/Kzr169b77zzjlWhQgXL29vbypcvn1W9enVr9OjRVkRERMJx0dHRVr9+/Sx/f38rd+7cVkhIiHXw4EELsN5+++2E4+KnX9+5um68lP483OtaJif+6yf3uPPvZefOna3HHnvsrp8p7s1hWenwXzcRN/HUU0+xd+/eVI0FkLQRFxdHwYIFadeuXZJdH1lZREQEJUuWZNy4cfTu3du2Onbt2kXVqlX54osvUrSYn6s5c+YMJUqUYO7cuWqRycQ0RkayrNOnT7N48WJ69OhhdymZ3rVr1xJ1d82aNYuLFy863aJADD8/P4YPH867776bYXccv3r1aqJ9kyZNwsPDw2kguTuZNGkSDz/8sEJMJqcWGclywsPD2bhxIx9//DHbtm3jyJEjBAQE2F1WprZ27VoGDx5Mx44dyZ8/Pzt27OCTTz6hfPnybN++3WnhOLHH6NGj2b59Ow0bNsTLy4ulS5eydOlSnn/+eaZPn253eSLJ0mBfyXLWrVvHM888Q9GiRZk5c6ZCTAYoXrw4wcHBvP/++1y8eBF/f3969uzJ22+/rRDjIurUqcOKFSt48803uXz5MkWLFmXUqFFOs6BEXJFaZERERMRtaYyMiIiIuC0FGREREXFbmX6MTFxcHKdOnSJPnjy6aZiIiIibsCyLqKgoAgMD77rgZKYPMqdOnfpbN0YTERER+5w4ceKuN3PN9EEm/uZpJ06cwNfX1+ZqREREJCUiIyMJDg6+513gM32Qie9O8vX1VZARERFxM/caFqLBviIiIuK2FGRERETEbSnIiIiIiNtSkBERERG3pSAjIiIibktBRkRERNyWgoyIiIi4LQUZERERcVsKMiIiIuK2Mv3KviIiIpL2YmNhwwY4fRqKFIF69cDTM+PrsLVFZuzYsTzyyCPkyZOHQoUKERISwsGDB52OadCgAQ6Hw+nx4osv2lSxiIiIzJsHxYtDw4bQrZv5s3hxsz+j2Rpk1q1bR79+/diyZQsrVqzgxo0bPPHEE0RHRzsd99xzz3H69OmEx7hx42yqWEREJGubNw86dICTJ533//GH2Z/RYcbWrqVly5Y5bc+YMYNChQqxfft2Hn/88YT9OXPmJCAgIKPLExERkdvExsLAgWBZZjs7MTRgLT/QDMsChwMGDYK2bTOum8mlBvtGREQA4O/v77R/9uzZFChQgIoVKzJixAiuXLmS7GfExMQQGRnp9BAREZG/b8OGWy0xDuKYRU+W05wBvA+YgHPihDkuo7jMYN+4uDgGDRpE3bp1qVixYsL+bt26UaxYMQIDA9mzZw///Oc/OXjwIPOSabsaO3Yso0ePzqiyRUREsozTp+OfWbzHUDrzNdfJxn4qJHNc+nNYVnwDkb369OnD0qVL+fHHHwkKCkr2uNWrV9O4cWMOHz5MqVKlEr0eExNDTExMwnZkZCTBwcFERETg6+ubLrWLiIhkBWvXmoG9QxnPeF4GoCtzmEtXp+PWrIEGDf7e14qMjMTPz++ev79dokWmf//+LFq0iPXr1981xADUqlULINkg4+3tjbe3d7rUKSIikpXVqwf9/Wcz/qIJMUMZ7xRiHA4ICjLHZRRbg4xlWQwYMICwsDDWrl1LiRIl7vmeXbt2AVCkSJF0rk5ERERu57lmJf+NfAaAiQxmAkMTXnM4zJ+TJmXsejK2Bpl+/foxZ84cFixYQJ48eThz5gwAfn5+5MiRgyNHjjBnzhxatmxJ/vz52bNnD4MHD+bxxx+nUqVKdpYuIiKStezcCU89hcfNG5yo24WJR8fDH7deDgoyIaZdu4wty9YxMo74+HaHzz77jF69enHixAmefvpp9u3bR3R0NMHBwTz11FO8+uqrKR7vktI+NhEREUlGeDjUrg1nz5pBMkuXEuvlna4r+6b097fLDPZNLwoyIiIif8P581CnDhw6BJUqwfr14OeX7l82pb+/XWodGREREXEh0dHQurUJMcWKwdKlGRJiUkNBRkRERBK7eRO6dIGffgJ/f1i2DAID7a4qEQUZERERcWZZ8OKLsGgR+PjAwoVQrpzdVSVJQUZEREScjRoFn3wCHh7w1VdmjIyLUpARERGRW6ZPhzfeMM+nTYM2beyt5x4UZERERMRYsAD69jXPR46E556zt54UUJARERER2LTJDO6NizMBZuRIuytKEQUZERGRrO7AAXjySbh2zfw5Zcqtew64OAUZERGRrOzUKWjWDC5ehEcfhblzwcsl7imdIgoyIiIiWVVEBLRoAcePQ5kyZpp1zpx2V5UqCjIiIiJZUUwMPPUU7NkDAQGwfDkUKGB3VammICMiIpLVxMVBaCisWQN58phbDxQvbndV90VBRkREJCuxLBg61Cx0ly0bhIVBlSp2V3XfFGRERESykvfeg0mTzPOZM6FxY1vL+bsUZERERLKK2bPh5ZfN8/HjoWtXe+tJAwoyIiIiWcHKlfDMM+b54MGmeykTUJARERHJ7HbuNDOUbtwwq/eOH293RWlGQUZERCQzCw83a8VcvgwNG8KMGeau1plE5jkTERERcXb+vFm19+xZqFTJzFDy9ra7qjSlICMiIpIZRUdD69Zw6BAUK2bWivHzs7uqNKcgIyIiktncvGnGwvz0E/j7w7JlEBhod1XpQkFGREQkM7EsePFFWLQIfHzM/ZPKlbO7qnSjICMiIpKZjBoFn3xiBvR+9RXUqWN3RelKQUZERCSzmD4d3njDPJ86Fdq0sbeeDKAgIyIikhksWAB9+5rnr78Ozz9vbz0ZREFGRETE3W3aZAb3xsXBP/5hupeyCAUZERERd3bgADz5JFy7ZqZbT50KDofdVWUYBRkRERF3deqUWfDu4kWoVQvmzgUvL7urylAKMiIiIu4oIsLceuD4cShTxky3zpXL7qoynIKMiIiIu4mJMTeB3LMHAgLMgncFCthdlS0UZERERNxJXByEhsKaNZAnDyxZAiVK2F2VbRRkRERE3MmwYWahu2zZYN48qFrV7opspSAjIiLiLt57DyZONM9nzIAmTWwtxxUoyIiIiLiDOXNMawzAu+9Ct2721uMiFGRERERc3apV0KuXeT54MAwdams5rkRBRkRExJXt2mVmKN24YVbvHT8+Sy14dy8KMiIiIq4qPNysFRMVBQ0bmnExHvrVfTt9N0RERFzR+fPQvDmcOQOVKkFYGHh7212Vy1GQERERcTVXrpj7J/32GxQrBkuXgp+f3VW5JAUZERERV3LzJnTuDFu2gL+/WbU3MNDuqlyWgoyIiIirsCx48UVz3yQfH1i4EMqVs7sql6YgIyIi4ipGjYJPPjEDer/6CurUsbsil6cgIyIi4gqmT4c33jDPp06FNm3srcdNKMiIiIjYbcEC6NvXPH/9dXj+eXvrcSMKMiIiInbatMksdBcXB//4h+lekhRTkBEREbHLgQNmmvW1a9C6telS0qq9qaIgIyIiYodTp6BZM7h4EWrVgrlzwcvL7qrcjoKMiIhIRouIMLceOH4cypQx061z5bK7KrekICMiIpKRYmLMTSD37IGAALPgXYECdlflthRkREREMkpcHISGwpo1kCcPLFkCJUrYXZVbU5ARERHJKMOGmYXusmWDefOgalW7K3J7CjIiIiIZ4b33YOJE83zGDGjSxNZyMgsFGRERkfQ2Z45pjQF4913o1s3eejIRBRkREZH0tGoV9Oplng8aBEOH2llNpqMgIyIikl527TIzlG7cgM6dTfeSFrxLUwoyIiIi6SE83KwVExUFDRvCzJnmrtaSpvQdFRERSWvnz0Pz5nDmDFSqBGFh4O1td1WZkoKMiIhIWrpyxdw/6bffoGhRWLoU/PzsrirTUpARERFJKzdvmrEwW7ZAvnxm1d7AQLurytRsDTJjx47lkUceIU+ePBQqVIiQkBAOHjzodMy1a9fo168f+fPnJ3fu3LRv356zZ8/aVLGIiEgyLAv69DH3TfLxMX+WL293VZmerUFm3bp19OvXjy1btrBixQpu3LjBE088QXR0dMIxgwcPZuHChXzzzTesW7eOU6dO0a5dOxurFhERScLo0fDxx2ZA79y5UKeO3RVlCQ7Lsiy7i4h37tw5ChUqxLp163j88ceJiIigYMGCzJkzhw4dOgBw4MABypcvz+bNm3n00Ufv+ZmRkZH4+fkRERGBr69vep+CiIhkRR9+CC+8YJ5Pm3brudy3lP7+dqkxMhEREQD4+/sDsH37dm7cuEGT25ZxLleuHEWLFmXz5s1JfkZMTAyRkZFODxERkXTz/femSwngtdcUYjKYywSZuLg4Bg0aRN26dalYsSIAZ86cIXv27OTNm9fp2MKFC3PmzJkkP2fs2LH4+fklPIKDg9O7dBERyao2b4YuXcxdrXv3Nt1LkqFcJsj069ePffv2MXfu3L/1OSNGjCAiIiLhceLEiTSqUERE5DYHDkDr1nD1KrRqZbqUtGpvhvOyuwCA/v37s2jRItavX09QUFDC/oCAAK5fv86lS5ecWmXOnj1LQEBAkp/l7e2NtxYdEhGR9HTqlFnw7uJFqFkTvvoKvFziV2qWY2uLjGVZ9O/fn7CwMFavXk2JEiWcXq9evTrZsmVj1apVCfsOHjzI8ePHqV27dkaXKyIiAhER0LIlHDsGZcrA4sWQK5fdVWVZtsbHfv36MWfOHBYsWECePHkSxr34+fmRI0cO/Pz86N27N0OGDMHf3x9fX18GDBhA7dq1UzRjSUREJE3FxEC7drB7NwQEmAXvChSwu6oszdYgM3XqVAAaNGjgtP+zzz6j1//f8nzixIl4eHjQvn17YmJiaNasGVOmTMngSkVEJMuLi4PQUFi9GvLkgSVL4I6eBMl4LrWOTHrQOjIiIpImhgyBiRMhWzYTYm5bGkTSnluuIyMiIuKS3nvPhBiAGTMUYlyIgoyIiMjdzJkDw4aZ5+++C9262VuPOFGQERERSc6qVfD/YzYZNAiGDrWzGkmCgoyIiEhSdu2Cp56CGzegc2fTvaQF71yOgoyIiMidwsOhRQuIioKGDWHmTHNXa3E5uioiIiK3O3/erNp75gxUqgRhYaAV412WgoyIiEi8K1fgySfht9+gaFFYuhT8/OyuSu5CQUZERATg5k0zFmbLFsiXz6zaGxhod1VyDwoyIiIilgV9+sCiReDjY/4sX97uqiQFFGRERERGj4aPPzYDeufOhTp17K5IUkhBRkREsrYPPzRBBmDKFGjb1t56JFUUZEREJOv6/nvTpQTw2mvwwgv21iOppiAjIiJZ0+bN0KWLuat17963WmXErSjIiIhI1nPgALRuDVevQqtWMG2aVu11UwoyIiKStZw6ZRa8u3gRataEr74CLy+7q5L7pCAjIiJZR0QEtGwJx45B6dJmmnWuXHZXJX+DgoyIiGQNMTHQrh3s3g2FC8Py5VCwoN1Vyd+kICMiIplfXBz06gWrV0Pu3ObWAyVK2F2VpAEFGRERyfxeftksdOflBfPmQdWqdlckaURBRkREMrcJE8wDYMYMaNrU1nIkbSnIiIhI5vXllzB0qHk+bhx0725vPZLmFGRERCRzWrUKQkPN84EDYdgwe+uRdKEgIyIimc+uXfDUU3DjBnTqZLqWtOBdpqQgIyIimcvRo9CiBURFQYMGMGuWuau1ZEq6siIiknmcP29W7T1zBh5+GObPB29vu6uSdKQgIyIimcOVK/Dkk3DwIBQtataK8fOzuypJZwoyIiLi/m7ehM6dYcsWyJcPli2DBx6wuyrJAAoyIiLi3iwL+vQx903y8YGFC6F8eburkgyiICMiIu5t9Gj4+GMzoPfLL6FuXbsrkgykICMiIu7rww9NkAGYMgVCQmwtRzKegoyIiLin7783XUoAr70GL7xgbz1iCwUZERFxP5s3Q5cu5q7WvXvfapWRLEdBRkRE3MuBA9C6NVy9Cq1awbRpWrU3C1OQERER93HqlFnw7uJFqFkTvvoKvLzsrkpspCAjIiLuISICWraEY8egdGkz3TpXLrurEpspyIiIiOuLiYF27WD3bihcGJYvh4IF7a5KXICCjIiIuLa4OOjVC1avhty5za0HSpSwuypxEQoyIiLi2l5+GebONWNh5s2DqlXtrkhciIKMiIi4rgkTzANgxgxo2tTWcsT1KMiIiIhr+vJLGDrUPB83Drp3t7cecUkKMiIi4npWrYLQUPN84EAYNszeesRlKciIiIhr2bULnnoKbtyATp1M15IWvJNkKMiIiIjrOHoUWrSAqCho0ABmzTJ3tRZJhn46RETENVy4YFbtPXMGHn4Y5s8Hb2+7qxIXp3WdRUTEFrGxsGEDnD4ND+S7Qr1RrXEcPAhFi5q1Yvz87C5R3ICCjIiIZLh588wY3pMnwZObzKMLDrZwPXc+si9bBg88YHeJ4ibUtSQiIhlq3jzo0MGEGLCYQl/asJCr+NDo8kLm/Vre7hLFjSjIiIhIhomNNS0xlmW2X+cNnucjYvGgK1+yyVGXQYPMcSIpoSAjIiIZZsOGWy0x/2IMoxkFQD8ms4AQLAtOnDDHiaSExsiIiEiGOX0avLjBVPrwDz4BYCSjmM6LiY4TSQkFGRERyTBBvpEsoiPN+IFYPBjA/5hK30THFSliQ3HilhRkREQkY5w8yWP/aoWDPUSTk858xWJaOx3icEBQENSrZ1ON4nYUZEREJP3t2gWtWuE4dYpreQOof2kROxzVwbp1SPxdCCZNAk9PO4oUd6TBviIikr6WLzdNLKdOQYUK+Ozawr++q55oqZigIPj2W2jXzp4yxT2pRUZERNLPRx9Bnz5mPnWjRvDdd5A3L+2KQdu2t1b2LVLEZB21xEhqKciIiEjai4uDV1+FsWPNdmgofPghZM+ecIinp7kvpMjfoSAjIiJpKyYGnnkGvvzSbI8aBa+/fmsQjEgaUpAREZG0c/EihISYPiMvL/j4Y9MaI5JOFGRERCRt/P47tGwJBw+aO1fPm2fGxYikI1tnLa1fv54nn3ySwMBAHA4H8+fPd3q9V69eOBwOp0fz5s3tKVZERJL300/w6KMmxBQtChs3KsRIhrA1yERHR1O5cmUmT56c7DHNmzfn9OnTCY8v4/tcRUTENYSFmVG7585BtWqwZQtUqGB3VZJF2Nq11KJFC1q0aHHXY7y9vQkICMigikREJFUmTYIhQ8ztrFu1grlzIXduu6uSLMTlF8Rbu3YthQoVomzZsvTp04cLFy7c9fiYmBgiIyOdHiIiksZiY2HgQBg82ISYPn1g/nyFGMlwLh1kmjdvzqxZs1i1ahXvvPMO69ato0WLFsTGxib7nrFjx+Ln55fwCA4OzsCKRUSygOhos/zu+++b7XffhcmTzSwlkQzmsCzLuvdh6c/hcBAWFkZISEiyx/z++++UKlWKlStX0rhx4ySPiYmJISYmJmE7MjKS4OBgIiIi8PX1TeuyRUSylrNn4cknYds28PaGzz+Hjh3trkoyocjISPz8/O75+9ulW2TuVLJkSQoUKMDhw4eTPcbb2xtfX1+nh4iIpIFffzUzk7Ztg/z5YfVqhRixnVsFmZMnT3LhwgWKFClidykiIlnL2rVQpw4cPQoPPmhmJtWpY3dVIvbOWrp8+bJT60p4eDi7du3C398ff39/Ro8eTfv27QkICODIkSMMHz6cBx98kGbNmtlYtYhIFvPFF/Dss3DjhgkvCxZAgQJ2VyUC2Nwi8/PPP1O1alWqVq0KwJAhQ6hatSqvv/46np6e7NmzhzZt2lCmTBl69+5N9erV2bBhA97e3naWLSKSNVgWvPUW9OhhQkzHjrBqlUKMuBSXGeybXlI6WEhERG5z4wa8+CJ8+qnZfvllePtt8HCrEQnixlL6+1tz5URExFlEhGl9WbHCBJcPPjDrxIi4IAUZERG55cQJs0Lv3r2QKxd8/bW5EaSIi1KQERERY9cuE2JOnYIiRWDRInPvJBEXps5OERGBpUuhXj0TYipUMNOrFWLEDSjIiIhkdR9+aFbrvXwZGjeGjRuhaFG7qxJJEQUZEZGsKi4ORoyAF14wN4Hs1QuWLAE/P7srE0kxjZEREcmKrl2DZ56BuXPN9ujR8Npr4HDYW5dIKinIiIhkNRcuQEgI/PgjZMsGH38MPXvaXZXIfVGQERHJSo4cMdOpf/vNdCHNmweNGtldlch9U5AREckqtmwxg3rPnzeDeZcsMTOURNyYBvuKiGQF8+ZBw4YmxFSvDj/9pBAjmYKCjIhIZmZZMHEidOhgBvi2bg1r10JAgN2ViaQJBRkRkcwqNhZeegmGDDGBpl8/mD8fcue2uzKRNKMxMiIimVF0NHTtCgsXminV48fD4MGaXi2ZjoKMiEhmc+aMGdT788/g4wNffAHt29tdlUi6UJAREclMfvnFTK8+dgwKFIDvv4fate2uSiTdpHiMzKlTp9KzDhER+bvWrIE6dUyIKV0aNm9WiJFML8VBpkKFCsyZMyc9axERkfv1+efQrBlEREDduibEPPig3VWJpLsUB5kxY8bwwgsv0LFjRy5evJieNYmISEpZFrz5prnFwI0b0KkTrFwJ+fPbXZlIhkhxkOnbty979uzhwoULPPTQQyxcuDA96xIRkXu5cQN694bXXzfb//wnfPmlGeArkkWkarBviRIlWL16NR988AHt2rWjfPnyeHk5f8SOHTvStEAREUlCRIRZ5G7lSvDwgClT4IUX7K5KJMOletbSsWPHmDdvHvny5aNt27aJgoyIiKSz48ehVSvYtw9y5YKvvzYzlUSyoFSlkI8++oihQ4fSpEkT9u/fT8GCBdOrLhERScrOnSbEnD4NRYrA4sVQtardVYnYJsVBpnnz5mzdupUPPviAnj17pmdNIiKSlCVLzGDe6GioWNGEmKJF7a5KxFYpDjKxsbHs2bOHoKCg9KxHRESSMm2auVdSXBw0aQLffgt+fnZXJWK7FAeZFStWpGcdIiKSlLg4GDECxo0z2716wYcfQrZstpYl4io0UldExFVduwahoWYwL8Abb8Crr+rGjyK3UZAREXFFFy5A27awcaNpffn0U3j6aburEnE5CjIiIq7m8GEznfrQITMOJiwMGja0uyoRl6QgIyLiSjZvhjZt4Px5KFbMzFR66CG7qxJxWSm+RYGIiKSz776DRo1MiKlRA7ZsUYgRuQcFGRERu1kWvPcedOxoBvg++SSsXQsBAXZXJuLyFGREROx08yYMGADDhplA07+/GROTK5fdlYm4BY2RERGxS3Q0dOkCixaZKdXvvQeDBml6tUgqKMiIiNjh9GnThbR9O/j4wOzZ0K6d3VWJuB0FGRGRjLZ/v5leffw4FCgACxfCo4/aXZWIW9IYGRGRjLR6NdSta0JMmTJmZpJCjMh9U5AREckos2ZB8+YQEQGPPQabNkGpUnZXJeLWFGRERNKbZZn7JIWGwo0b0LkzrFgB+fPbXZmI21OQERFJT9evw7PPwsiRZvuVV2DOHDPAV0T+Ng32FRFJL5cuQYcOsGoVeHrClCnw/PN2VyWSqSjIiIikh+PHzcyk/fshd274+mto0cLuqkQyHQUZEZG0tmMHtGoFZ85AYCAsXgxVqthdlUimpDEyIiJpafFiePxxE2IefthMr1aIEUk3CjIiImll6lRo08bceqBpU9iwAYKD7a5KJFNTkBER+bvi4uDll6FvX/P82WdNy4yfn92ViWR6GiMjIvJ3XL1q1of55huz/eab8O9/68aPIhlEQUZE5H6dPw9t25oVerNlg08/haeftrsqkSxFQUZE5H4cPmymUx8+DHnzQlgYNGhgd1UiWY6CjIhIam3aZAb1XrgAxYvDkiVQvrzdVYlkSRrsKyKSGt98A40amRBTo4aZXq0QI2IbBRkRkZSwLBg/Hjp1gpgYMzZm7VooXNjuykSyNAUZEZF7uXkT+vUzU6wBXnoJvvsOcuWyty4R0RgZEZG7unwZunQx68I4HDBhAgwaZHdVIvL/FGRERJJz+jS0bm3uneTjA3PmwFNP2V2ViNxGQUZEJCn795u7Vx8/DgULwsKFUKuW3VWJyB00RkZE5E6rVkGdOibElCkDmzcrxIi4KAUZEZHbzZwJzZtDZCTUq2dCTKlSdlclIslQkBERATO9etQo6NXLzFLq0gV++AH8/e2uTETuwtYgs379ep588kkCAwNxOBzMnz/f6XXLsnj99dcpUqQIOXLkoEmTJhw6dMieYkUk87p+3QSY0aPN9ogRMHu2GeArIi7N1iATHR1N5cqVmTx5cpKvjxs3jvfff59p06bx008/kStXLpo1a8a1a9cyuFIRybQuXTL3TJo1Czw94cMP4T//AQ81WIu4A1tnLbVo0YIWLVok+ZplWUyaNIlXX32Vtm3bAjBr1iwKFy7M/Pnz6dKlS0aWKiKZ0bFjZmbSL79A7tzm9gPNm9tdlYikgsv+lyM8PJwzZ87QpEmThH1+fn7UqlWLzZs3J/u+mJgYIiMjnR4iIols3w6PPmpCzAMPwI8/KsSIuCGXDTJnzpwBoPAd9zEpXLhwwmtJGTt2LH5+fgmP4ODgdK1TRNzQokXw+ONw5gxUqmRu/Fi5st1Vich9cNkgc79GjBhBREREwuPEiRN2lyQirmTKFHPDxytX4IknYMMGCAqyuyoRuU8uG2QCAgIAOHv2rNP+s2fPJryWFG9vb3x9fZ0eIiLExZmbPvbrZ5737m1aZvRvhIhbc9kgU6JECQICAli1alXCvsjISH766Sdq165tY2Ui4nauXoXOnWH8eLM9Zgx89BFky2ZvXSLyt9k6a+ny5cscPnw4YTs8PJxdu3bh7+9P0aJFGTRoEG+99RalS5emRIkSvPbaawQGBhISEmJf0SLiXs6dM11JmzdD9uzw2WfQrZvdVYlIGrE1yPz88880bNgwYXvIkCEAhIaGMmPGDIYPH050dDTPP/88ly5d4rHHHmPZsmX4aJEqEUmJQ4fMGjFHjkC+fBAWBvXr212ViKQhh2VZlt1FpKfIyEj8/PyIiIjQeBmRrGTjRtMSc+ECFC8OS5dCuXJ2VyUiKZTS398uO0ZGROS+ff01NG5sQswjj5jp1QoxIpmSgoyIZB6WBePGmYG9MTGmRWbtWrhjPSoRyTxsHSMjInK/YmPNEjCnT0ORIlCv9k08Bw2AadPMAS+9BBMmmPsniUimpSAjIm5n3jwYOBBOnjTbubjMAp/ONL62BBwOmDjRHCAimZ6CjIi4lXnzoEMH04sEUIRTLKI11a7t5Ao52P3yHGoPDLG1RhHJOBojIyJuIzbWNLTEh5gK7GMLj1KNnfxJQRqxhs5fhhAba2+dIpJxFGRExG1s2GC6kzy5yUAmsZnaFOUEByjLo2zhJ2px4oQ5TkSyBnUtiYjbOH0aarCN6bxANXYCsJqGdOBb/sLf6TgRyRrUIiMi7iEignrfDOAnalGNnfxFXp5nOk1Y6RRiwMxiEpGsQS0yIuLaLAu+/RYGDiTo/5tavqA7Q3mPP3FeH8bhgKAgqFfPjkJFxA5qkRER1xUeDq1aQadOpr/owQfZ8PoKejq+4JwjcYgBmDRJS8eIZCUKMiLiem7cgLffhgoVzD2SsmeH11+HvXupN7oJ334LDzzg/JagINNw066dPSWLiD3UtSQiruXHH+HFF2H/frPdoAFMnep0r6R27czdB5xW9q2nlhiRrEhBRkRcw8WLMHw4fPKJ2S5QAN57D3r0uNVvdBtPT5NxRCRrU5AREXtZFnz+OQwdCufPm329e8M770D+/PbWJiIuT0FGROxz8CD07QurV5vthx4yN33UtCMRSSEN9hWRjHftGowcCZUqmRDj4wP/+Q/s3KkQIyKpohYZEclYq1ZBnz5w6JDZbt4cJk+GkiXtrUtE3JJaZEQkY/z5Jzz9NDRpYkJMQAB89RUsWaIQIyL3TUFGRNJXXBx8+CGULQuzZ5sZSP36wYEDZqG7JGYkiYiklLqWRCT97N1r1oTZtMlsV6kC06dDzZq2liUimYdaZEQk7UVHwz//CdWqmRCTKxdMnAjbtinEiEiaUouMiKStxYtN19GxY2Y7JATefx+Cg20tS0QyJ7XIiEja+OMP6NABWrc2IaZoUViwAMLCFGJEJN0oyIjI3xMba1pcypeH774z9w4YNszcK6lNG7urE5FMTl1LInL/tm+HF14wfwLUqmUG81aubG9dIpJlqEVGRFIvMhIGDjQDd7dvBz8/c4fqTZsUYkQkQ6lFRkRSzrJg3jx46SU4dcrs69oVJkwwC9yJiGQwBRkRSZmjR81spCVLzHapUjBlCjzxhK1liUjWpq4lEbm7Gzdg3DhzZ+olSyBbNnj1VbPYnUKMiNhMLTIikrxNm8zKvHv3mu3HH4dp08wMJRERF6AWGRFJ7OJFMxupbl0TYvLnh88+g7VrFWJExKWoRUZEbrEsc2PHIUPg3Dmz75lnTNdSgQL21iYikgQFGRExfvsN+vaFVavMdvnyphvp8cftrUtE5C7UtSSS1cXEwBtvQKVKJsT4+MBbb8GuXQoxIuLy1CIjkpWtWWMG8/72m9l+4gkzpbpUKXvrEhFJIbXIiGRF585Bz57QqJEJMYULw5dfwrJlCjEi4lYUZESykrg4+PhjKFsWPv8cHA7o0wcOHIAuXcy2iIgbUdeSSFaxf7/pRvrxR7NdubK5wWOtWvbWJSLyN6hFRiSzu3IFRoyAKlVMiMmVC8aPh59/VogREbenFhmRzGzpUnN/pPBws922Lbz/PhQtam9dIiJpRC0yIpnRqVPQqRO0bGlCTFAQhIXB/PkKMSKSqSjIiGQmsbHwwQdmMbtvvgEPDxg8GH75BUJC7K5ORCTNqWtJJLPYscPcH+nnn812zZpmZd6qVe2tS0QkHalFRsTdRUWZVpdHHjEhxtcXJk82d65WiBGRTE4tMiLuyrLMmJeXXoKTJ82+zp1h4kQoUsTW0kREMoqCjIg7OnYMBgyAhQvNdokS5tYCzZvbW5eISAZT15KIO7lxA959Fx56yISYbNngX/+CffsUYkQkS1KLjIi72LLFDObds8ds16tnBvM+9JC9dYmI2EgtMiKu7q+/zP2Q6tQxIcbfHz75BNauVYgRkSxPLTIirsqyzB2pBw+GP/80+0JDTddSwYL21iYi4iIUZERc0eHD0LcvrFhhtsuWNd1IDRrYWpaIiKtR15KIK4mJgTffhIoVTYjx9oY33oDduxViRESSoBYZEVexdq0ZC3PggNlu0sRMqS5d2tayRERcmVpkROx2/jz06gUNG5oQU6gQzJ4NP/ygECMicg8KMiJ2sSz49FMz/mXmTLPvhRdMmOnWDRwOe+sTEXED6loSscMvv8CLL8KGDWb74Ydh+nSoXdveukRE3IxaZEQy0tWr8O9/Q5UqJsTkzAnjxsH27QoxIiL3QS0yIhll+XIzpfr3381269bwwQdQrJi9dYmIuDGXbpEZNWoUDofD6VGuXDm7yxJJndOnoUsXcy+k33+HBx6AefPg++8VYkRE/iaXb5GpUKECK1euTNj28nL5kkWM2Fgz7mXECIiMBA8Pc8fqN9+EPHnsrk5EJFNw+VTg5eVFQECA3WWIpM6uXWYG0tatZrtGDRNqqlWztSwRkczGpbuWAA4dOkRgYCAlS5ake/fuHD9+/K7Hx8TEEBkZ6fQQyTCXL8PQoSa4bN1qWl7+9z9z52qFGBGRNOfSQaZWrVrMmDGDZcuWMXXqVMLDw6lXrx5RUVHJvmfs2LH4+fklPIKDgzOwYsnSFiwwd6OeMMF0K3XsaNaE6d8fPD3trk5EJFNyWJZl2V1ESl26dIlixYoxYcIEevfuneQxMTExxMTEJGxHRkYSHBxMREQEvr6+GVWqZCXHj8NLL5kgA1C8OEyeDC1b2lqWiIg7i4yMxM/P756/v11+jMzt8ubNS5kyZTh8+HCyx3h7e+Pt7Z2BVUmWdfMm/Pe/MHIkREeDlxcMGwavvWbWhxERkXTn0l1Ld7p8+TJHjhyhSJEidpciWd1PP5lxMMOGmRBTty7s3AljxyrEiIhkIJcOMsOGDWPdunUcPXqUTZs28dRTT+Hp6UnXrl3tLk2yqogI6NfPrMK7ezfkywcffQTr10PFinZXJyKS5bh019LJkyfp2rUrFy5coGDBgjz22GNs2bKFggUL2l2aZDWWBV99BYMHw5kzZl+PHjB+vLlbtYiI2MKlg8zcuXPtLkEEjhwxtxb44QezXaYMTJ0KjRrZW5eIiLh215KIra5fhzFjTJfRDz9A9uwwapTpUlKIERFxCS7dIiNim/Xr4cUX4ddfzXajRqYVpkwZe+sSEREnCjKSJcXGwoYN5n6ORYpAvXr/v2bd+fMwfDh89pk5sGBBs8Bd9+7gcNhas4iIJKYgI1nOvHkwcCCcPHlrX9ADFmEhM6kxdxhcuGB2PvccvP02+PvbU6iIiNyTgoxkKfPmQYcOZhJSvLIcYNofL1Jj8jqzo2JFmDbNrA0jIiIuTYN9JcuIjTUtMfEhxoervMFr7KESDVjHFXIw1u9tYrftUIgREXETapGRLGPDBjh50qIaOwhlJt2YQwFMN9JiWtKfDzgaUYLaW6BBA3trFRGRlFGQkazh9Gn8PprNHmbyMPsSdh8nmCFM4DvaA474Q0VExE0oyEjmde0afP89zJwJy5ZRNS7O7Mab+YQwk1BW0JTYO/4a6FZeIiLuQ0FGMhfLMjd0nDkT5s6FS5duvfRobUYcCOXDS534i3yJ3upwQFCQmYotIiLuQUFGMoeTJ+Hzz02AOXjw1v6gIOjZE3r2xFG2LDXnwbgOphPp9plL8UvETJr0/+vJiIiIW1CQEfd15QqEhZnwsnLlrWSSIwe0bw+hodCwoVMyadcOvv02iXVkgkyIadcuY09BRET+HgUZcS+WBT/+aMLL119DVNSt1x5/3ISXDh3A1zfZj2jXDtq2TWZlXxERcSsKMuIejh6FWbPM48iRW/tLlEjoOqJkyRR/nKenpliLiGQGCjLiui5fNv1AM2fC2rW39ufODR07mtaXevXAQ+s6iohkVQoy4lri4kxomTkTvvsOoqPNfofD3IE6NNT0DeXKZWuZIiLiGhRkxDUcPmzCy6xZcPz4rf0PPgi9ekGPHlC0qG3liYiIa1KQEftERJgBuzNnwsaNt/b7+kKXLqb1pXbtW3OjRURE7qAgIxkrNhZWrYIZM8zU6WvXzH4PD2ja1LS+tG1rplCLiIjcg4KMZIxffzUtL198AX/8cWv/Qw+Zlpenn4bAQPvqExERt6QgI+nn4kVzm4CZM2Hr1lv78+WDbt1MgKlRQ11HIiJy3xRkJG3dvAnLl5uuo++/h+vXzX5PT2jZ0oSX1q3B29vWMkVEJHNQkJG0sXevCS+zZ8PZs7f2V6pkxr106waFC9tVnYiIZFIKMnL/zp2DL780AWbnzlv7CxaE7t1N60uVKnZVJyIiWYCCjKTO9euwZIkJL4sXm64kgGzZ4MknTXhp0cJsi4iIpDMFGbk3yzItLjNmwJw5cOHCrdeqVzddR126QIECdlUoIiJZlIKMJO/MGTNdeuZM2Lfv1v6AALPSbmgoVKhgX30iIpLlKciIs2vXYOFC0/qyfLlZwA7MLKO2bU3rS9Om4KUfHRERsZ9+G4npOtq61YSXuXPh0qVbrz36qAkvnTqZ9V9ERERciIJMVnbypOk6mjEDDh68tT8oCHr2NI+yZW0rT0RE5F4UZLKaK1dg/nwTXlauNK0xYO5t1L69GffSsKFZwE5ERMTFKchkBZZl7i49cyZ89RVERd16rV4903XUoYO567SIiIgbUZDJzI4dg1mzTIA5cuTW/uLFTctLz55QsqRt5YmIiPxdCjKZzeXL8N13JrysWXNrf65c0LGjaX2pVw88PGwrUUREJK0oyGQGcXGwbp0JL99+C9HRZr/DYca79OoF7dqZMCMiIpKJKMi4s8OHTdfRrFmmGynegw+arqMePaBYMfvqExERSWcKMu4mIgK++ca0vvz44639vr7QubNpfald27TGiIiIZHIKMu4gNhZWrTJTpsPCzOq7YMa5NG1qwkvbtmYKtYiISBaiIOPKDhwwLS+ffw5//HFrf/nypuvo6afhgQfsq09ERMRmCjKu5q+/zG0CZswwtw2Ily8fdOtmAkyNGuo6EhERQUHGNdy8aW7QOHMmLFgA16+b/Z6e0KKF6Tpq3drcuFFEREQSKMjYae9eE16++ALOnr21v1IlE166dYPChW0rT0RExNUpyGS08+dhzhwTYHbsuLW/QAHo3t0EmCpV7KpORETErSjIZITr12HJEhNeFi0yXUkA2bKZLqNevUwXUrZstpYpIiLibhRk7kNsLGzYAKdPQ5EiZsX/RDeLtizYudOElzlzTEtMvOrVzaDdrl1NS4yIiIjcFwWZVJo3DwYOhJMnb+0LCoL//tfcBYAzZ2D2bBNg9u69dVBAgJkuHRoKFStmeN0iIiKZkYJMKsybBx06mMaW250/eY257RdSu/pMiuxaZppswMwyatvWhJcnngAvfbtFRETSkn6zplBsrGmJuRViLB5hG72YQRfm4s9fsP3/X3r0URNeOnc267+IiIhIulCQSaENG5y7k76lA+2Zl7B9giA+pweNZ4ZSq2dZGyoUERHJejzsLsBdnD7tvL2JOlwhB1/QnSasoDhH+Tf/4fdsCjEiIiIZRS0yKVSkiPP2hzzPRzxHFL53PU5ERETSj1pkUqhePTM7Kf4WR5fJ4xRiHA4IDjbHiYiISMZQkEkhT08zxRoS368xfnvSpCTWkxEREZF0oyCTCu3awbffwgMPOO8PCjL727Wzpy4REZGsSmNkUqldO7M0zD1X9hUREZF0pyBzHzw9oUEDu6sQERERdS2JiIiI21KQEREREbelICMiIiJuyy2CzOTJkylevDg+Pj7UqlWLrVu32l2SiIiIuACXDzJfffUVQ4YMYeTIkezYsYPKlSvTrFkz/vzzT7tLExEREZu5fJCZMGECzz33HM888wwPPfQQ06ZNI2fOnHz66ad2lyYiIiI2c+kgc/36dbZv306TJk0S9nl4eNCkSRM2b96c5HtiYmKIjIx0eoiIiEjm5NJB5vz588TGxlK4cGGn/YULF+bMmTNJvmfs2LH4+fklPIKDgzOiVBEREbGBSweZ+zFixAgiIiISHidOnLC7JBEREUknLr2yb4ECBfD09OTs2bNO+8+ePUtAQECS7/H29sbb2zth27IsAHUxiYiIuJH439vxv8eT49JBJnv27FSvXp1Vq1YREhICQFxcHKtWraJ///4p+oyoqCgAdTGJiIi4oaioKPz8/JJ93aWDDMCQIUMIDQ2lRo0a1KxZk0mTJhEdHc0zzzyTovcHBgZy4sQJ8uTJg8PhSLO6IiMjCQ4O5sSJE/j6+qbZ57qSzH6Omf38IPOfo87P/WX2c9T53T/LsoiKiiIwMPCux7l8kOncuTPnzp3j9ddf58yZM1SpUoVly5YlGgCcHA8PD4KCgtKtPl9f30z5w3m7zH6Omf38IPOfo87P/WX2c9T53Z+7tcTEc/kgA9C/f/8UdyWJiIhI1pHpZi2JiIhI1qEgc5+8vb0ZOXKk0wypzCazn2NmPz/I/Oeo83N/mf0cdX7pz2Hda16TiIiIiItSi4yIiIi4LQUZERERcVsKMiIiIuK2FGRERETEbSnIJGP9+vU8+eSTBAYG4nA4mD9//j3fs3btWqpVq4a3tzcPPvggM2bMSPc671dqz2/t2rU4HI5Ej+TuQm63sWPH8sgjj5AnTx4KFSpESEgIBw8evOf7vvnmG8qVK4ePjw8PP/wwS5YsyYBq78/9nOOMGTMSXUMfH58Mqjh1pk6dSqVKlRIW2qpduzZLly6963vc6fql9vzc6dol5e2338bhcDBo0KC7HudO1/BOKTlHd7qOo0aNSlRruXLl7voeO66fgkwyoqOjqVy5MpMnT07R8eHh4bRq1YqGDRuya9cuBg0axD/+8Q+WL1+ezpXen9SeX7yDBw9y+vTphEehQoXSqcK/Z926dfTr148tW7awYsUKbty4wRNPPEF0dHSy79m0aRNdu3ald+/e7Ny5k5CQEEJCQti3b18GVp5y93OOYFbgvP0aHjt2LIMqTp2goCDefvtttm/fzs8//0yjRo1o27Yt+/fvT/J4d7t+qT0/cJ9rd6dt27Yxffp0KlWqdNfj3O0a3i6l5wjudR0rVKjgVOuPP/6Y7LG2XT9L7gmwwsLC7nrM8OHDrQoVKjjt69y5s9WsWbN0rCxtpOT81qxZYwHWX3/9lSE1pbU///zTAqx169Yle0ynTp2sVq1aOe2rVauW9cILL6R3eWkiJef42WefWX5+fhlXVBrLly+f9fHHHyf5mrtfP8u6+/m567WLioqySpcuba1YscKqX7++NXDgwGSPdddrmJpzdKfrOHLkSKty5copPt6u66cWmTSyefNmmjRp4rSvWbNmbN682aaK0keVKlUoUqQITZs2ZePGjXaXk2IREREA+Pv7J3uMu1/DlJwjwOXLlylWrBjBwcH3bAFwFbGxscydO5fo6Ghq166d5DHufP1Scn7gnteuX79+tGrVKtG1SYq7XsPUnCO413U8dOgQgYGBlCxZku7du3P8+PFkj7Xr+rnFvZbcwZkzZxLdyLJw4cJERkZy9epVcuTIYVNlaaNIkSJMmzaNGjVqEBMTw8cff0yDBg346aefqFatmt3l3VVcXByDBg2ibt26VKxYMdnjkruGrjoO6HYpPceyZcvy6aefUqlSJSIiIhg/fjx16tRh//796Xpz1fu1d+9eateuzbVr18idOzdhYWE89NBDSR7rjtcvNefnbtcOYO7cuezYsYNt27al6Hh3vIapPUd3uo61atVixowZlC1bltOnTzN69Gjq1avHvn37yJMnT6Lj7bp+CjKSImXLlqVs2bIJ23Xq1OHIkSNMnDiRzz//3MbK7q1fv37s27fvrn277i6l51i7dm2n//HXqVOH8uXLM336dN588830LjPVypYty65du4iIiODbb78lNDSUdevWJfvL3t2k5vzc7dqdOHGCgQMHsmLFCpcdzPp33c85utN1bNGiRcLzSpUqUatWLYoVK8bXX39N7969bazMmYJMGgkICODs2bNO+86ePYuvr6/bt8Ykp2bNmi4fDvr378+iRYtYv379Pf+3k9w1DAgISM8S/7bUnOOdsmXLRtWqVTl8+HA6Vff3ZM+enQcffBCA6tWrs23bNv773/8yffr0RMe64/VLzfndydWv3fbt2/nzzz+dWmxjY2NZv349H3zwATExMXh6ejq9x92u4f2c451c/TreLm/evJQpUybZWu26fhojk0Zq167NqlWrnPatWLHirv3d7m7Xrl0UKVLE7jKSZFkW/fv3JywsjNWrV1OiRIl7vsfdruH9nOOdYmNj2bt3r8texzvFxcURExOT5Gvudv2Scrfzu5OrX7vGjRuzd+9edu3alfCoUaMG3bt3Z9euXUn+gne3a3g/53gnV7+Ot7t8+TJHjhxJtlbbrl+6DiV2Y1FRUdbOnTutnTt3WoA1YcIEa+fOndaxY8csy7KsV155xerRo0fC8b///ruVM2dO6+WXX7Z+/fVXa/LkyZanp6e1bNkyu07hrlJ7fhMnTrTmz59vHTp0yNq7d681cOBAy8PDw1q5cqVdp3BXffr0sfz8/Ky1a9dap0+fTnhcuXIl4ZgePXpYr7zySsL2xo0bLS8vL2v8+PHWr7/+ao0cOdLKli2btXfvXjtO4Z7u5xxHjx5tLV++3Dpy5Ii1fft2q0uXLpaPj4+1f/9+O07hrl555RVr3bp1Vnh4uLVnzx7rlVdesRwOh/XDDz9YluX+1y+15+dO1y45d87ocfdrmJR7naM7XcehQ4daa9eutcLDw62NGzdaTZo0sQoUKGD9+eeflmW5zvVTkElG/HTjOx+hoaGWZVlWaGioVb9+/UTvqVKlipU9e3arZMmS1meffZbhdadUas/vnXfesUqVKmX5+PhY/v7+VoMGDazVq1fbU3wKJHVugNM1qV+/fsL5xvv666+tMmXKWNmzZ7cqVKhgLV68OGMLT4X7OcdBgwZZRYsWtbJnz24VLlzYatmypbVjx46MLz4Fnn32WatYsWJW9uzZrYIFC1qNGzdO+CVvWe5//VJ7fu507ZJz5y95d7+GSbnXObrTdezcubNVpEgRK3v27NYDDzxgde7c2Tp8+HDC665y/RyWZVnp2+YjIiIikj40RkZERETcloKMiIiIuC0FGREREXFbCjIiIiLithRkRERExG0pyIiIiIjbUpARERERt6UgIyIiIm5LQUZE3EpsbCx16tShXbt2TvsjIiIIDg7m3//+t02ViYgdtLKviLid3377jSpVqvDRRx/RvXt3AHr27Mnu3bvZtm0b2bNnt7lCEckoCjIi4pbef/99Ro0axf79+9m6dSsdO3Zk27ZtVK5c2e7SRCQDKciIiFuyLItGjRrh6enJ3r17GTBgAK+++qrdZYlIBlOQERG3deDAAcqXL8/DDz/Mjh078PLysrskEclgGuwrIm7r008/JWfOnISHh3Py5Em7yxERG6hFRkTc0qZNm6hfvz4//PADb731FgArV67E4XDYXJmIZCS1yIiI27ly5Qq9evWiT58+NGzYkE8++YStW7cybdo0u0sTkQymFhkRcTsDBw5kyZIl7N69m5w5cwIwffp0hg0bxt69eylevLi9BYpIhlGQERG3sm7dOho3bszatWt57LHHnF5r1qwZN2/eVBeTSBaiICMiIiJuS2NkRERExG0pyIiIiIjbUpARERERt6UgIyIiIm5LQUZERETcloKMiIiIuC0FGREREXFbCjIiIiLithRkRERExG0pyIiIiIjbUpARERERt6UgIyIiIm7r/wDGS9V4Zy/J0AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [0.0000000e+00 4.4408921e-16 1.0000000e+00]\n",
      "Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generating sample data\n",
    "X = np.array([[1], [2], [3], [4], [5]])  \n",
    "Y = np.array([1, 4, 9, 16, 25])        \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)  \n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, Y_train)\n",
    "\n",
    "\n",
    "X_poly_test = poly.transform(X_test)\n",
    "Y_pred = model.predict(X_poly_test)\n",
    "\n",
    "plt.scatter(X, Y, color='blue') \n",
    "plt.plot(X, model.predict(poly.fit_transform(X)), color='red') \n",
    "plt.title('Polynomial Regression (Degree 2)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Model Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c75cc-dc3f-4179-b09c-a1731fc1377a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
